\section{Discussion}
Although combining structural MRI scans from different centres provides an opportunity to increase the statistical power of brain morphometric analyses in neurological and neuropsychiatric disorders, one important confound is the potential for site differences (scanner and MRI protocol effects) to introduce systematic errors. Thus, pooling data from different sites, scanners or acquisition protocols could make the interpretation of results difficult or even decrease predictive accuracy \citep{winterburn2017can,schnack2016detecting}. These site specific differences are even more important with the growing popularity of open source data and automatic diagnostic systems using machine learning techniques. Although naively pooling data from multiple centers may increase sample size and intuitively, increase predictive accuracy, we found that the decision boundary learned by the classifier is heavily biased towards the separating hyperplane of the scanner differences rather than the true diagnostic label (See Figure \ref{fig:svm_decision}).

We proposed a novel method using deep learning to correct (unknown) site differences and experimented with data from subjects differing in clinical diagnosis or gender . The dataset was collected at two different MRI sites with different hardware and protocols. As such, our dataset probably represents larger site-related differences than previous studies which used images acquired with similar MRI protocols \citep{kostro2014correction}. Even with these large differences, we were able to remove the majority of site effects without any apparent loss in classification accuracy. These results suggest that GAN models may be a powerful method to selectively remove unwanted information from image data, without affecting the information content related to features of interest (e.g., clinical diagnosis).

The GAN transformation left intact differences related to clinical diagnosis as well as gender. Such differences are likely to vary in magnitude relative to the site-related differences the GAN removed. For instance, VBM and MVPA indicates gray matter volume differences related to schizophrenia are small, heterogenous and widely-distributed \citep{mourao2005classifying,mourao2012individualized}. By comparison, gender differences are likely larger, with fewer major points of focus, but still widely-distributed \citep{ruigrok2014meta}. Demonstrating the selectivity of the GAN transformation against differences of varying magnitude is an important validation of the generalizability and utility of this method.

Perhaps not surprisingly, the GAN transformation produced the largest changes in the thalamus and brain stem. These regions may be more susceptible to distortions in magnetic fields and are notoriously difficult to achieve accurate image segmentation and registration during preprocessing \citep{good2001cerebral}. This is partly because it has a mix of gray and white matter which cannot be easily delineated by standard preprocessing steps. An implication of the regional variations in transformation we found is that one cannot assume that preprocessing removes all site-related differences in multi-site studies, even if bias-field correction is included. However at present it is hard to do more than speculate as to why the GAN transformation produced the changes where it did.

In comparison to other learning-based approaches, one advantage of neural networks is that no features have to be hand-crafted but instead, the model learns suitable features for the transformation during training automatically \citep{plis2014deep}. In contrast to methods such as linear regression that treat voxels independently of each other, convolutional neural networks take local information into account as they are based on image patches. The fully convolutional architecture allows for a variable number of input sizes however the quality of the generation of images may change due to the fixed receptive field of the networks.

The experiments suggest that using methods such as linear regression, and in some cases GP regression (see Table 5) are not suitable to correct for site differences. The linear regression included an intercept term to account for mean differences between sites. Yet it decreased classification accuracy when discriminating diagnostic groups and still allowed for differentiation between scanners.  On the other hand, the GAN method here was able to capture the differences between scanners, making the transformations indistinguishable between the scanner sets and improve classification accuracy compared to baseline. This suggests that site-related differences are highly nonlinear that cannot be estimated using linear methods.

The small difference in performance between the GAN and GP regression when classifying diagnostic groups could be explained by the fact we only used a single sagittal slice from each brain in our dataset. A single slice would likely contain a relatively restricted amount of variance and hence represent a limit to the amount of information that can be learned from the data. The GAN correction, however, increased classification of gender significantly compared to GP regression. Figure \ref{fig:transformation} shows that most of the changes between original and transformed images occur around the thalamus and brain stem. Since the structural differences between gender occur in these regions \citep{ruigrok2014meta} and the result of the transformation has improved the consistency of the GM maps in those regions across scanners, this allowed the classifier to learn a decision boundary that reflected gender differences rather than variation caused by scanner differences.

\subsection{Limitations}
The major limitation of the method described here is the restriction to 2D images. That is, the current training dataset only included a small set of mid-sagittal slices rather than the entire MRI brain volume, and the test dataset only included a single mid-sagittal slice from each volume. Future work is planned to generalize this method to 3D datasets (e.g., MRI brain volumes). The extension to brain volumes could include similar techniques proposed by \cite{wu2016learning} where convolutions are performed using 3D kernels instead of 2D. However, the extension to 3D convolutional networks is not straightforward as they require more kernels than can fit on currently available hardware, and so require advanced cache management for back propagation. An alternative method is to split volumes into 2D slice data which is used to train a 2D network. Although, this loses contextual information provided by the third dimension, this is considered as a form of data augmentation and has proved very successful in tasks such as brain segmentation \citep{gonzalez2016review} However, given the massive scientific gains offered by a valid method to pool datasets in a post-hoc manner, we also hope the details we describe here will inspire other researchers to pursue the same aim, and help any  researchers currently developing a similar solution. For this reason, all data, code and models used in the present report are provided for download at  \url{https://github.com/harrisonnguyen/mri_gan}.

One advantage of conventional regression methods to correct confounds is that they allow for the inclusion of subject-specific covariates such as age and sex. The proposed GAN on the other hand, does not control for covariates and only learns a mapping between scanners while maintaining subject variation. Instead, these covariates must be included as a pre- or post- processing step using standard regression techniques. The inclusion of covariates within the GAN is left as future work.
